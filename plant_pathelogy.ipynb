{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhavsharma0209/Plant-Pathology/blob/master/plant_pathelogy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "q3vmnkkcajuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "!pip install efficientnet\n",
        "from efficientnet.tfkeras import EfficientNetB7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsLSG93AajuV",
        "colab_type": "text"
      },
      "source": [
        " **TPU preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "fYC8-vzlajuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "print(\"REPLICAS: \", tpu_strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4oRYy_owajue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 800\n",
        "BATCH_SIZE = 8* tpu_strategy.num_replicas_in_sync\n",
        "classes = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quHZXIgLajuk",
        "colab_type": "text"
      },
      "source": [
        "**Loading data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp3ituPcFBHb",
        "_kg_hide-output": false,
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('/content/drive/My Drive/Plant/plant-pathology-2020-fgvc7.zip') as f:\n",
        "    print('Extracting')\n",
        "    f.extractall()\n",
        "    print('Done!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2x_dAt2wajul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gcs_path = 'gs://kds-4d598c666e2db12886904a0a2d808a1259db3c0910143721bab174d1'\n",
        "img_path = '/images/'\n",
        "\n",
        "train_csv = pd.read_csv('train.csv')\n",
        "labels = train_csv.iloc[:,1:].values\n",
        "\n",
        "images_path = np.array([f'{gcs_path}{img_path}{image_id}.jpg' for image_id in train_csv['image_id']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iZUN_q0ajuq",
        "colab_type": "text"
      },
      "source": [
        "**Split data into train and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy9IfoX0xIaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images, val_images, train_labels, val_labels = train_test_split(images_path ,labels , test_size=0.2, shuffle=True, random_state = 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIcTSaoVajuy",
        "colab_type": "text"
      },
      "source": [
        "**Class weights**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pwB68Ne9wJ4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = compute_class_weight('balanced', np.unique(np.argmax(labels, axis = 1)), np.argmax(labels, axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS_hEpnRaju6",
        "colab_type": "text"
      },
      "source": [
        "functions to image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BMgeNNroaju7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_image(filename, label=None):\n",
        "    bits = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(bits, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.image.resize(image, (IMG_SIZE,IMG_SIZE))\n",
        "\n",
        "    if label is None:\n",
        "        return image\n",
        "    else:\n",
        "        return image, label\n",
        "\n",
        "def data_augment(filename, label=None, seed=200):\n",
        "    image, label = decode_image(filename, label)\n",
        "    image = tf.image.random_flip_left_right(image, seed=seed)\n",
        "    image = tf.image.random_flip_up_down(image, seed=seed)\n",
        "    image = tf.image.rot90(image)\n",
        "           \n",
        "    if label is None:\n",
        "        return image\n",
        "    else:\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uggQ29lTajvB",
        "colab_type": "text"
      },
      "source": [
        "**Preparing train and validation sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KI96xP7JajvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((train_images, train_labels))\n",
        "    .map(data_augment, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .repeat()\n",
        "    .prefetch(AUTO)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QfAyF4NZajvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((val_images,val_labels))\n",
        "    .map(decode_image, num_parallel_calls=AUTO)\n",
        "    .batch(val_images.shape[0])\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        "     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1IsGnNoajvT",
        "colab_type": "text"
      },
      "source": [
        "**Model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dQG5l19YajvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(trainable = True):\n",
        "    \n",
        "    #Model structure\n",
        "    efficientnet = EfficientNetB7(weights = 'noisy-student', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling = 'avg')\n",
        "    output = Dense(classes, activation=\"softmax\")(efficientnet.output)\n",
        "\n",
        "    model = Model(inputs=efficientnet.input, outputs=output)\n",
        "\n",
        "    if trainable == False:\n",
        "        model.trainable = False\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H0M0GK7fajvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "    model = convnet()\n",
        "\n",
        "#Compilation of model\n",
        "model.compile(optimizer= Adam(0.0005), loss= 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xesmkgZ4ajve",
        "colab_type": "text"
      },
      "source": [
        "### **Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BbpOw--jajve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min')\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.6, patience = 2, mode = 'min', min_lr= 0.0000001)\n",
        "checkpoint = ModelCheckpoint(checkpoint_name, save_best_only= True, save_weights_only= True ,mode = 'min', monitor= 'val_loss', verbose = 1)\n",
        "#lr_schedule = LearningRateScheduler(schedule= lrschedule, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9xMIv2R1FaX",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEPS_PER_EPOCH = train_images.shape[0] // BATCH_SIZE\n",
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXe8N1ZTybP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_dict = {i:val  for i, val in enumerate(list(class_weights))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vCBhxCvwajvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_data=val_dataset,\n",
        "                    class_weight = class_dict,\n",
        "                    callbacks = [early_stopping, reduce_lr, checkpoint]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1a80eAg0ajvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_acc_plot(history, accuracy = False):\n",
        "    \n",
        "    data = pd.DataFrame(history.history)\n",
        "\n",
        "    plt.title('Training Loss vs Validation Loss')\n",
        "    plt.plot(data['loss'], c = 'b', label = 'loss', )\n",
        "    plt.plot(data['val_loss'], c = 'orange', label = 'val_loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    if accuracy == True:\n",
        "        plt.title('Training Accuracy vs Validation Accuracy')\n",
        "        plt.plot(data['accuracy'], c = 'b', label = 'accuracy')\n",
        "        plt.plot(data['val_accuracy'], c = 'orange', label = 'val_accuracy')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hgmOezjxIEG",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_acc_plot(history, accuracy= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Msk_J9Bfwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_pred = model.predict(val_dataset)\n",
        "\n",
        "def make_prediction_label(label_data):\n",
        "    \n",
        "    pred_label = np.zeros(shape = label_data.shape, dtype = 'int')\n",
        "    argmax = np.argmax(label_data, axis = 1)\n",
        "\n",
        "    for idx in range(label_data.shape[0]):\n",
        "        max_col = argmax[idx]\n",
        "        pred_label[idx][max_col] = int(1)\n",
        "\n",
        "    return pred_label\n",
        "\n",
        "pred_label = make_prediction_label(dev_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd2e0pkfBft8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_cm(true_labels, pred_labels, label_name):\n",
        "    max_true = np.argmax(true_labels, axis = 1)\n",
        "    max_pred = np.argmax(pred_labels, axis = 1)\n",
        "\n",
        "    assert true_labels.shape == pred_labels.shape\n",
        "\n",
        "    matrix = np.zeros(shape = (4,4), dtype = 'int')\n",
        "\n",
        "    for idx in range(true_labels.shape[0]):\n",
        "        matrix[max_true[idx]][max_pred[idx]] = matrix[max_true[idx]][max_pred[idx]] + 1\n",
        "    \n",
        "    matrix = pd.DataFrame(matrix, index = label_name, columns= label_name)\n",
        "\n",
        "    return matrix\n",
        "\n",
        "cm_matrix = plot_cm(val_labels, pred_label, ['h', 'm', 'r', 's'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMGG9UI-BfrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm_matrix"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}